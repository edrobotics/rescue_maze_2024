#!/usr/bin/env python3
import cv2
import logging
import loggingclass
#from ColorVision import *
#import tensorflow as tf
import numpy as np
import socket 
import os
import time
import platform

if platform.system() == "Linux":

    import tflite_runtime.interpreter as tflite
else:
    import tensorflow.lite as tflite




class letters:
    classes = ['H', 'S', 'U', 'none']
    def __init__(self,dir_path):
        self.dir_path = dir_path
        model_path = os.path.join(self.dir_path,"model.tflite")
        self.interpreter = tflite.Interpreter(model_path=model_path)
        self.interpreter.allocate_tensors()
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
    def recogniseSection(self,image):

        image = cv2.resize(image,(25,25))
        image = np.float32(image)
        image = np.expand_dims(image, axis=0)

        self.interpreter.set_tensor(self.input_details[0]['index'], image)

        self.interpreter.invoke()

        output_data = self.interpreter.get_tensor(self.output_details[0]['index'])
        print(output_data)
        percentage = output_data[0][np.argmax(output_data[0])] 
        victim = self.classes[np.argmax(output_data[0])]

        
        
        return victim, percentage



class comms:
    port = 4242
    host = socket.gethostbyname(socket.gethostname())
    s = socket.socket(socket.AF_INET,socket.SOCK_STREAM)

    def __init__(self,bComms = True):
        if bComms:
            self.s.connect((self.host, self.port))
            self.bComms = True
        else: self.bComms = False

    def send(self,messageType,victimType,camera,position,timeStamp):

        message = f"!{messageType},{victimType},{camera},{position},{timeStamp}"
        if self.bComms:
            self.s.send(message)








class imgproc:
    
    framedetected = []

    def __init__(self, bLogging, dir_path, bComms = True, training = False):
        print("initiating visionclass")
        self.dir_path = dir_path
        self.bLogging = bLogging
        self.log = loggingclass.log(base_dir=dir_path, bLogging = bLogging)
        self.training = training
        if training: 
            self.logTraining = loggingclass.log(base_dir=dir_path, bLogging = True,folder="training/autogenerated") 

        self.loadModel()
        self.com = comms(bComms=bComms)


    def do_the_work(self, image, camera):
        print("working")
        self.imagecopy = image.copy()
        self.image = image.copy()
        self.camera = camera
        self.timestamp = time.time()
        self.log.save_image(image, camera)
        self.find_visual(image)

    def cleanUp(self):
        self.framedetected = []

    def preprocessing(self,image):
        print("preprocessing")
        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
        binary = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,21,10) 
        binary = np.invert(binary)

        return binary

    def find_visual(self, image):
        binary = self.preprocessing(image)
        binary2 = binary.copy()
        contours, hierarchy = cv2.findContours(binary,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)
        cv2.drawContours(binary2, contours, 1, (255,0,0),3)
        print(len(contours))
        for contour in contours:
            area = cv2.contourArea(contour)
            if area >1337: 
                rect = cv2.minAreaRect(contour)
                box = cv2.boxPoints(rect)
                box = np.int0(box)
                cv2.drawContours(self.imagecopy, [box], 0, (255, 0, 0), 3)
                x,y,w,h = cv2.boundingRect(contour)
                self.vPos = (x,y)


                size = (25,25)
                potentialVictim = binary[y:y+h, x:x+w]
                potentialVictimRS = cv2.resize(potentialVictim, size)
                potentialVictimBGR = cv2.cvtColor(potentialVictimRS, cv2.COLOR_GRAY2BGR)
                self.identify_victim(potentialVictimBGR)


        #cv2.imshow("contours", binary2)
        #cv2.imshow("imagecopy",self.imagecopy)

                #return potentialVictimCS





    def loadModel(self):
        self.model = letters(self.dir_path)




    def identify_victim(self, section):
        victim, percentage = self.model.recogniseSection(section)
        if victim != "none": self.framedetected.append(victim)
        cv2.putText(self.imagecopy, f"{victim}, {percentage:.2f}",self.vPos,cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,255,0))
        if victim != "none" and percentage > 0.99:
            print(f"{victim} {percentage}") 
            self.com.send("C",victim,self.camera,self.vPos[0],self.timestamp)
            if self.training:
                self.logTraining.save_image(section, victim)




        







